<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modifica Dati Utente</title>
    <link rel="stylesheet" href="../static/style_infopage.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="../static/language.js" defer></script>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
</head>
<body>
    <header>
        <div class="burger-menu" onclick="toggleMobileMenu()">
            <div class="burger-line"></div>
            <div class="burger-line"></div>
            <div class="burger-line"></div>
        </div>
        <img src="/static/Unimol-logo.png" alt="logo">
        {% if session.logged_in %}
            <nav class="barra_navigazione">
                <a href="after_login.html">Home</a>
                <a id="nav_visualizza" href="visualizzanalisi.html">Visualizza analisi</a>
                <a id="nav_modifica" href="modifica_dati.html">Modifica dati</a>
                <a id="nav_info" href="infopage.html">Dettagli</a>
                <a id="nav_canc" href="elimina_dati.html">Elimina</a>
                <a href="{{ url_for('logout') }}" id="btnlogout">
                    <span id="nav_esci">Logout</span>
                </a>
            </nav>
            {% else %}
            <!-- L'utente non Ã¨ loggato, reindirizzalo alla pagina di login -->
            <script>window.location = "{{ url_for('errorpage') }}";</script>
            {% endif %}

        <div id="language-buttons-mobile">
            <div class="dropdown">
                <button class="dropbtn" onclick="toggleDropdownMobile()">
                    <span id="seleziona_lingua_mobile">Seleziona la lingua</span>
                </button>
                <div class="dropdown-content" id="languageDropdownMobile">
                    <button data-lang="en" onclick="selectLanguage('en')">English</button>
                    <button data-lang="it" onclick="selectLanguage('it')">Italiano</button>
                </div>
            </div>
        </div>

        <div id="mobileMenu" class="mobile-menu">
            <a  href="after_login.html">Home</a>
            <a id="nav_visualizza_mobile" href="visualizzanalisi.html">Visualizza analisi</a>
            <a id="nav_modifica_mobile" href="modifica_dati.html">Modifica dati</a>
            <a id="nav_info_mobile" href="infopage.html">Dettagli</a>
            <a id="nav_canc_mobile" href="elimina_dati.html">Elimina</a>
            <a href="login">
                <span>Logout</span>
            </a>
        </div>

        
    </header>
    <div id="language-buttons-container">
        <div id="language-buttons">
            <div class="dropdown">
                <button class="dropbtn" onclick="toggleDropdown()" >
                    <span id="seleziona_lingua">Seleziona la lingua</span>
                </button>
                <div class="dropdown-content" id="languageDropdown">
                    <button data-lang="en" onclick="selectLanguage('en')">English</button>
                    <button data-lang="it" onclick="selectLanguage('it')">Italiano</button>
                </div>
            </div>
        </div>
    </div>

    <form>
        <h2 id="titolo_info">Project Information</h2>
            <p class="info-title">1. Dataset</p>
            <p class="info-text">The dataset used in this project consists of 25,000 color images in .jpeg format, including 10,000 related to adenocarcinomas and benign tissues of the colon, and 15,000 related to lung adenocarcinomas, squamous cell lung carcinomas, and benign lung tissues.
        
                Specifically, the dataset contains 750 images of lung tissue, including 250 of healthy lung tissue, 250 of lung adenocarcinomas, and 250 of squamous cell carcinomas, complying with HIPAA regulations.
        
                All images were subsequently cropped using the Python programming language, obtaining square dimensions of 768x768 pixels from the original 1024x768 pixels.
        
                Subsequently, the images were augmented using the Augmentor software package, which allowed an expansion of the dataset to 15,000 images, through the following augmentations: left and right rotations (up to 25 degrees) and horizontal and vertical flips.</p>
            
            <p class="info-title">2. Classification</p>
            <p class="info-text">To perform the classification, a Deep Learning architecture called Standard CNN was used, composed of a convolutional layer, a pooling layer, and a fully connected layer.
                <br>
                2.1 Training phase
                <br>
                The model was trained with the following hyperparameters:
                <br>
                epochs = 50; batch_size = 32; learning_rate = 0.0001; size_img = 110x3; Execution time = 1:00:17 (HH:MM:SS)
                Dataset split into 80-10-10 (training-validation-test)
                <br>
                lung aca : 4000-499-500 -> 4999
                <br>
                lung_n : 4000-499-500 -> 4999
                <br>
                lung_scc : 4000-499-500 -> 4999
                <br><br>
                <strong><a href="https://arxiv.org/pdf/1912.12142.pdf">https://arxiv.org/pdf/1912.12142.pdf</a></strong>
                <br><br>
                2.2 Test phase
                <br>
                test loss: 0.081;
                <br>
                test accuracy: 0.982 Prec: 0.982 Recall: 0.982
                <br>
                F-Measure: 0.982 AUC: 0.995
                <br>

                <br></p>
                <p class="info-title">3. Grad-CAM</p>
                <p class="info-text">Grad-CAM (Gradient-weighted Class Activation Mapping) is a visualization technique used to understand which parts of an image are important for a neural network's decision. This method is particularly useful for interpreting the results of deep learning models, allowing to identify salient regions on which the model relies to make a prediction.
                    
                In the context of the provided algorithm, Grad-CAM is implemented to generate an activation map that highlights the regions of the image that have the greatest influence on the model's prediction. This activation map is obtained by calculating the gradients of the output layer with respect to the feature maps of the previous convolutional layer. Regions with higher gradients indicate greater importance for the model's prediction.
                    
                Once the activation map is calculated, a color transformation is applied to highlight the significant regions. The most important areas are usually represented with warm colors like yellow or red, while less important areas can be represented with cooler colors like blue or green. This coloring helps to clearly visualize the salient regions of the image.</p>

    </form>

    <script>
        // JavaScript per gestire il menu burger
function toggleMobileMenu() {
    var mobileMenu = document.getElementById("mobileMenu");
    mobileMenu.classList.toggle("show"); // Mostra o nasconde il menu a tendina
}

// JavaScript per chiudere il menu a tendina quando si clicca fuori da esso
window.onclick = function(event) {
    if (!event.target.matches('.burger-menu')) {
        var mobileMenu = document.getElementById("mobileMenu");
        if (mobileMenu.classList.contains('show')) {
            mobileMenu.classList.remove('show');
        }
    }
};
    </script>
</body>
</html>
